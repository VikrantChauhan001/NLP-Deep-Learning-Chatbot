{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for story, question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add(\"no\")\n",
    "vocab.add(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_len = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max(all_story_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'put': 1,\n",
       " 'left': 2,\n",
       " 'bathroom': 3,\n",
       " 'took': 4,\n",
       " 'is': 5,\n",
       " 'back': 6,\n",
       " 'bedroom': 7,\n",
       " 'journeyed': 8,\n",
       " 'discarded': 9,\n",
       " 'john': 10,\n",
       " 'hallway': 11,\n",
       " 'down': 12,\n",
       " 'travelled': 13,\n",
       " 'there': 14,\n",
       " 'daniel': 15,\n",
       " 'kitchen': 16,\n",
       " 'dropped': 17,\n",
       " 'apple': 18,\n",
       " 'got': 19,\n",
       " '?': 20,\n",
       " 'picked': 21,\n",
       " 'the': 22,\n",
       " 'yes': 23,\n",
       " 'football': 24,\n",
       " 'to': 25,\n",
       " '.': 26,\n",
       " 'up': 27,\n",
       " 'moved': 28,\n",
       " 'went': 29,\n",
       " 'grabbed': 30,\n",
       " 'in': 31,\n",
       " 'milk': 32,\n",
       " 'sandra': 33,\n",
       " 'office': 34,\n",
       " 'no': 35,\n",
       " 'garden': 36,\n",
       " 'mary': 37}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_sequence = tokenizer.texts_to_sequences(train_story_text)\n",
    "# train_question_sequence = tokenizer.texts_to_sequences(train_question_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index = tokenizer.word_index, max_story_len = max_story_len, max_question_len = max_question_len):\n",
    "    x = []\n",
    "    xq = []\n",
    "    y = []\n",
    "    for story, question, answer in data:\n",
    "        x_temp = [word_index[word.lower()] for word in story]\n",
    "        xq_temp = [word_index[word.lower()] for word in question]        \n",
    "        y_temp = np.zeros(len(word_index)+1)\n",
    "        y_temp[word_index[answer]] = 1\n",
    "        x.append(x_temp)\n",
    "        xq.append(xq_temp)        \n",
    "        y.append(y_temp)\n",
    "    return (pad_sequences(x,maxlen = max_story_len),pad_sequences(xq,maxlen = max_question_len), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded], axes = (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = Activation(\"softmax\")(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match, input_encoded_c])\n",
    "response = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dense(vocab_size)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation(\"softmax\")(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence, question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikra\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "10000/10000 [==============================] - 4s 403us/step - loss: 0.9230 - accuracy: 0.5034 - val_loss: 0.6967 - val_accuracy: 0.5030\n",
      "Epoch 2/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.7051 - accuracy: 0.5024 - val_loss: 0.6939 - val_accuracy: 0.4970\n",
      "Epoch 3/200\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.6961 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 4/200\n",
      "10000/10000 [==============================] - 3s 334us/step - loss: 0.6950 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 5/200\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.6938 - accuracy: 0.4994 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 6/200\n",
      "10000/10000 [==============================] - 3s 327us/step - loss: 0.6951 - accuracy: 0.4967 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
      "Epoch 7/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.6943 - accuracy: 0.5057 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 8/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.6943 - accuracy: 0.5030 - val_loss: 0.6932 - val_accuracy: 0.5040\n",
      "Epoch 9/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.6941 - accuracy: 0.5014 - val_loss: 0.6935 - val_accuracy: 0.4980\n",
      "Epoch 10/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.6934 - accuracy: 0.5124 - val_loss: 0.6935 - val_accuracy: 0.5050\n",
      "Epoch 11/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.6724 - accuracy: 0.5775 - val_loss: 0.6078 - val_accuracy: 0.7010\n",
      "Epoch 12/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.5324 - accuracy: 0.7531 - val_loss: 0.4559 - val_accuracy: 0.7910\n",
      "Epoch 13/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.4496 - accuracy: 0.8086 - val_loss: 0.4143 - val_accuracy: 0.8200\n",
      "Epoch 14/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.4064 - accuracy: 0.8332 - val_loss: 0.4208 - val_accuracy: 0.8420\n",
      "Epoch 15/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.3778 - accuracy: 0.8430 - val_loss: 0.4008 - val_accuracy: 0.8290\n",
      "Epoch 16/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.3673 - accuracy: 0.8497 - val_loss: 0.3781 - val_accuracy: 0.8300\n",
      "Epoch 17/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.3580 - accuracy: 0.8539 - val_loss: 0.3689 - val_accuracy: 0.8420\n",
      "Epoch 18/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.3442 - accuracy: 0.8588 - val_loss: 0.3687 - val_accuracy: 0.8420\n",
      "Epoch 19/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.3362 - accuracy: 0.8598 - val_loss: 0.3641 - val_accuracy: 0.8280\n",
      "Epoch 20/200\n",
      "10000/10000 [==============================] - 3s 313us/step - loss: 0.3300 - accuracy: 0.8599 - val_loss: 0.3685 - val_accuracy: 0.8290\n",
      "Epoch 21/200\n",
      "10000/10000 [==============================] - 3s 317us/step - loss: 0.3270 - accuracy: 0.8627 - val_loss: 0.3596 - val_accuracy: 0.8410\n",
      "Epoch 22/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.3169 - accuracy: 0.8640 - val_loss: 0.3373 - val_accuracy: 0.8440\n",
      "Epoch 23/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.3116 - accuracy: 0.8649 - val_loss: 0.3432 - val_accuracy: 0.8280\n",
      "Epoch 24/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.3116 - accuracy: 0.8659 - val_loss: 0.3759 - val_accuracy: 0.8160\n",
      "Epoch 25/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.3119 - accuracy: 0.8628 - val_loss: 0.3416 - val_accuracy: 0.8390\n",
      "Epoch 26/200\n",
      "10000/10000 [==============================] - 3s 312us/step - loss: 0.3048 - accuracy: 0.8651 - val_loss: 0.3455 - val_accuracy: 0.8410\n",
      "Epoch 27/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.3049 - accuracy: 0.8654 - val_loss: 0.3351 - val_accuracy: 0.8470\n",
      "Epoch 28/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.3032 - accuracy: 0.8690 - val_loss: 0.3342 - val_accuracy: 0.8360\n",
      "Epoch 29/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2989 - accuracy: 0.8678 - val_loss: 0.3330 - val_accuracy: 0.8360\n",
      "Epoch 30/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.3026 - accuracy: 0.8661 - val_loss: 0.3321 - val_accuracy: 0.8410\n",
      "Epoch 31/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2997 - accuracy: 0.8672 - val_loss: 0.3416 - val_accuracy: 0.8380\n",
      "Epoch 32/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2976 - accuracy: 0.8654 - val_loss: 0.3295 - val_accuracy: 0.8440\n",
      "Epoch 33/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2971 - accuracy: 0.8704 - val_loss: 0.3282 - val_accuracy: 0.8440\n",
      "Epoch 34/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2945 - accuracy: 0.8664 - val_loss: 0.3388 - val_accuracy: 0.8370\n",
      "Epoch 35/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2921 - accuracy: 0.8723 - val_loss: 0.3254 - val_accuracy: 0.8450\n",
      "Epoch 36/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2908 - accuracy: 0.8716 - val_loss: 0.3446 - val_accuracy: 0.8340\n",
      "Epoch 37/200\n",
      "10000/10000 [==============================] - 3s 316us/step - loss: 0.2929 - accuracy: 0.8714 - val_loss: 0.3335 - val_accuracy: 0.8380\n",
      "Epoch 38/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2895 - accuracy: 0.8713 - val_loss: 0.3367 - val_accuracy: 0.8440\n",
      "Epoch 39/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.2893 - accuracy: 0.8707 - val_loss: 0.3347 - val_accuracy: 0.8450\n",
      "Epoch 40/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2904 - accuracy: 0.8696 - val_loss: 0.3278 - val_accuracy: 0.8440\n",
      "Epoch 41/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2882 - accuracy: 0.8705 - val_loss: 0.3401 - val_accuracy: 0.8440\n",
      "Epoch 42/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2840 - accuracy: 0.8731 - val_loss: 0.3310 - val_accuracy: 0.8390\n",
      "Epoch 43/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2861 - accuracy: 0.8703 - val_loss: 0.3530 - val_accuracy: 0.8420\n",
      "Epoch 44/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.2830 - accuracy: 0.8737 - val_loss: 0.3797 - val_accuracy: 0.8310\n",
      "Epoch 45/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2855 - accuracy: 0.8745 - val_loss: 0.3266 - val_accuracy: 0.8440\n",
      "Epoch 46/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.2836 - accuracy: 0.8739 - val_loss: 0.3368 - val_accuracy: 0.8330\n",
      "Epoch 47/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.2838 - accuracy: 0.8740 - val_loss: 0.3313 - val_accuracy: 0.8350\n",
      "Epoch 48/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2837 - accuracy: 0.8718 - val_loss: 0.3341 - val_accuracy: 0.8410\n",
      "Epoch 49/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.2826 - accuracy: 0.8708 - val_loss: 0.3461 - val_accuracy: 0.8360\n",
      "Epoch 50/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2841 - accuracy: 0.8711 - val_loss: 0.3345 - val_accuracy: 0.8380\n",
      "Epoch 51/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2785 - accuracy: 0.8728 - val_loss: 0.3432 - val_accuracy: 0.8370\n",
      "Epoch 52/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2752 - accuracy: 0.8748 - val_loss: 0.3567 - val_accuracy: 0.8400\n",
      "Epoch 53/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2796 - accuracy: 0.8735 - val_loss: 0.3323 - val_accuracy: 0.8380\n",
      "Epoch 54/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2809 - accuracy: 0.8737 - val_loss: 0.3523 - val_accuracy: 0.8380\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2764 - accuracy: 0.8736 - val_loss: 0.3538 - val_accuracy: 0.8400\n",
      "Epoch 56/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.2749 - accuracy: 0.8729 - val_loss: 0.3417 - val_accuracy: 0.8400\n",
      "Epoch 57/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.2733 - accuracy: 0.8743 - val_loss: 0.3462 - val_accuracy: 0.8350\n",
      "Epoch 58/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.2726 - accuracy: 0.8771 - val_loss: 0.3534 - val_accuracy: 0.8310\n",
      "Epoch 59/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.2662 - accuracy: 0.8799 - val_loss: 0.3624 - val_accuracy: 0.8340\n",
      "Epoch 60/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2721 - accuracy: 0.8759 - val_loss: 0.3643 - val_accuracy: 0.8330\n",
      "Epoch 61/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2712 - accuracy: 0.8787 - val_loss: 0.3483 - val_accuracy: 0.8310\n",
      "Epoch 62/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2702 - accuracy: 0.8805 - val_loss: 0.3492 - val_accuracy: 0.8350\n",
      "Epoch 63/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2669 - accuracy: 0.8784 - val_loss: 0.3871 - val_accuracy: 0.8330\n",
      "Epoch 64/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2691 - accuracy: 0.8781 - val_loss: 0.3472 - val_accuracy: 0.8350\n",
      "Epoch 65/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2629 - accuracy: 0.8831 - val_loss: 0.3486 - val_accuracy: 0.8330\n",
      "Epoch 66/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.2616 - accuracy: 0.8845 - val_loss: 0.3462 - val_accuracy: 0.8370\n",
      "Epoch 67/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2634 - accuracy: 0.8807 - val_loss: 0.3519 - val_accuracy: 0.8350\n",
      "Epoch 68/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.2631 - accuracy: 0.8793 - val_loss: 0.3596 - val_accuracy: 0.8300\n",
      "Epoch 69/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.2564 - accuracy: 0.8839 - val_loss: 0.3884 - val_accuracy: 0.8360\n",
      "Epoch 70/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2639 - accuracy: 0.8805 - val_loss: 0.3914 - val_accuracy: 0.8310\n",
      "Epoch 71/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2657 - accuracy: 0.8783 - val_loss: 0.3974 - val_accuracy: 0.8250\n",
      "Epoch 72/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.2573 - accuracy: 0.8864 - val_loss: 0.4134 - val_accuracy: 0.8330\n",
      "Epoch 73/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.2549 - accuracy: 0.8845 - val_loss: 0.3729 - val_accuracy: 0.8420\n",
      "Epoch 74/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2575 - accuracy: 0.8840 - val_loss: 0.3577 - val_accuracy: 0.8380\n",
      "Epoch 75/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.2543 - accuracy: 0.8835 - val_loss: 0.3620 - val_accuracy: 0.8400\n",
      "Epoch 76/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2571 - accuracy: 0.8880 - val_loss: 0.3710 - val_accuracy: 0.8350\n",
      "Epoch 77/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2559 - accuracy: 0.8856 - val_loss: 0.3993 - val_accuracy: 0.8340\n",
      "Epoch 78/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2520 - accuracy: 0.8889 - val_loss: 0.3880 - val_accuracy: 0.8370\n",
      "Epoch 79/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.2504 - accuracy: 0.8833 - val_loss: 0.3982 - val_accuracy: 0.8300\n",
      "Epoch 80/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2497 - accuracy: 0.8869 - val_loss: 0.3975 - val_accuracy: 0.8270\n",
      "Epoch 81/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.2508 - accuracy: 0.8893 - val_loss: 0.4453 - val_accuracy: 0.8300\n",
      "Epoch 82/200\n",
      "10000/10000 [==============================] - 3s 312us/step - loss: 0.2444 - accuracy: 0.8909 - val_loss: 0.4064 - val_accuracy: 0.8370\n",
      "Epoch 83/200\n",
      "10000/10000 [==============================] - 3s 317us/step - loss: 0.2434 - accuracy: 0.8897 - val_loss: 0.3819 - val_accuracy: 0.8340\n",
      "Epoch 84/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2450 - accuracy: 0.8900 - val_loss: 0.3918 - val_accuracy: 0.8390\n",
      "Epoch 85/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2462 - accuracy: 0.8875 - val_loss: 0.4073 - val_accuracy: 0.8290\n",
      "Epoch 86/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2414 - accuracy: 0.8891 - val_loss: 0.4319 - val_accuracy: 0.8200\n",
      "Epoch 87/200\n",
      "10000/10000 [==============================] - 3s 313us/step - loss: 0.2397 - accuracy: 0.8914 - val_loss: 0.4323 - val_accuracy: 0.8300\n",
      "Epoch 88/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2425 - accuracy: 0.8902 - val_loss: 0.4247 - val_accuracy: 0.8250\n",
      "Epoch 89/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2387 - accuracy: 0.8900 - val_loss: 0.4045 - val_accuracy: 0.8300\n",
      "Epoch 90/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2396 - accuracy: 0.8923 - val_loss: 0.4117 - val_accuracy: 0.8310\n",
      "Epoch 91/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2426 - accuracy: 0.8904 - val_loss: 0.4272 - val_accuracy: 0.8290\n",
      "Epoch 92/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.2430 - accuracy: 0.8950 - val_loss: 0.4535 - val_accuracy: 0.8310\n",
      "Epoch 93/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2331 - accuracy: 0.8949 - val_loss: 0.5042 - val_accuracy: 0.8280\n",
      "Epoch 94/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2374 - accuracy: 0.8949 - val_loss: 0.4114 - val_accuracy: 0.8330\n",
      "Epoch 95/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2372 - accuracy: 0.8931 - val_loss: 0.4411 - val_accuracy: 0.8360\n",
      "Epoch 96/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2322 - accuracy: 0.8967 - val_loss: 0.4764 - val_accuracy: 0.8330\n",
      "Epoch 97/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2291 - accuracy: 0.8970 - val_loss: 0.4565 - val_accuracy: 0.8300\n",
      "Epoch 98/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2332 - accuracy: 0.8965 - val_loss: 0.4105 - val_accuracy: 0.8360\n",
      "Epoch 99/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.2314 - accuracy: 0.8966 - val_loss: 0.4960 - val_accuracy: 0.8260\n",
      "Epoch 100/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2314 - accuracy: 0.8976 - val_loss: 0.4416 - val_accuracy: 0.8280\n",
      "Epoch 101/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.2270 - accuracy: 0.8956 - val_loss: 0.4773 - val_accuracy: 0.8320\n",
      "Epoch 102/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2286 - accuracy: 0.8980 - val_loss: 0.4849 - val_accuracy: 0.8330\n",
      "Epoch 103/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2215 - accuracy: 0.9014 - val_loss: 0.4370 - val_accuracy: 0.8300\n",
      "Epoch 104/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2224 - accuracy: 0.8989 - val_loss: 0.4878 - val_accuracy: 0.8350\n",
      "Epoch 105/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2273 - accuracy: 0.8996 - val_loss: 0.4573 - val_accuracy: 0.8290\n",
      "Epoch 106/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.2304 - accuracy: 0.8977 - val_loss: 0.4673 - val_accuracy: 0.8350\n",
      "Epoch 107/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2214 - accuracy: 0.9014 - val_loss: 0.4492 - val_accuracy: 0.8310\n",
      "Epoch 108/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.2256 - accuracy: 0.8998 - val_loss: 0.4685 - val_accuracy: 0.8380\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.2206 - accuracy: 0.9009 - val_loss: 0.4761 - val_accuracy: 0.8390\n",
      "Epoch 110/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.2213 - accuracy: 0.9016 - val_loss: 0.4499 - val_accuracy: 0.8300\n",
      "Epoch 111/200\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.2220 - accuracy: 0.9022 - val_loss: 0.4890 - val_accuracy: 0.8280\n",
      "Epoch 112/200\n",
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.2194 - accuracy: 0.9049 - val_loss: 0.4686 - val_accuracy: 0.8230\n",
      "Epoch 113/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.2187 - accuracy: 0.9024 - val_loss: 0.4945 - val_accuracy: 0.8320\n",
      "Epoch 114/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.2160 - accuracy: 0.9045 - val_loss: 0.5111 - val_accuracy: 0.8340\n",
      "Epoch 115/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2190 - accuracy: 0.9059 - val_loss: 0.5248 - val_accuracy: 0.8340\n",
      "Epoch 116/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.2124 - accuracy: 0.9060 - val_loss: 0.4878 - val_accuracy: 0.8300\n",
      "Epoch 117/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.2127 - accuracy: 0.9069 - val_loss: 0.4844 - val_accuracy: 0.8350\n",
      "Epoch 118/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.2134 - accuracy: 0.9063 - val_loss: 0.4941 - val_accuracy: 0.8380\n",
      "Epoch 119/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.2128 - accuracy: 0.9025 - val_loss: 0.4854 - val_accuracy: 0.8340\n",
      "Epoch 120/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.2114 - accuracy: 0.9070 - val_loss: 0.5111 - val_accuracy: 0.8350\n",
      "Epoch 121/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2079 - accuracy: 0.9075 - val_loss: 0.4959 - val_accuracy: 0.8350\n",
      "Epoch 122/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.2071 - accuracy: 0.9058 - val_loss: 0.5420 - val_accuracy: 0.8320\n",
      "Epoch 123/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2101 - accuracy: 0.9093 - val_loss: 0.5220 - val_accuracy: 0.8380\n",
      "Epoch 124/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.2070 - accuracy: 0.9113 - val_loss: 0.5399 - val_accuracy: 0.8350\n",
      "Epoch 125/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.2041 - accuracy: 0.9104 - val_loss: 0.5149 - val_accuracy: 0.8260\n",
      "Epoch 126/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.2041 - accuracy: 0.9109 - val_loss: 0.5236 - val_accuracy: 0.8400\n",
      "Epoch 127/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.2088 - accuracy: 0.9075 - val_loss: 0.4999 - val_accuracy: 0.8340\n",
      "Epoch 128/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2071 - accuracy: 0.9098 - val_loss: 0.5473 - val_accuracy: 0.8360\n",
      "Epoch 129/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2021 - accuracy: 0.9125 - val_loss: 0.4808 - val_accuracy: 0.8300\n",
      "Epoch 130/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.2035 - accuracy: 0.9121 - val_loss: 0.5252 - val_accuracy: 0.8360\n",
      "Epoch 131/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2003 - accuracy: 0.9118 - val_loss: 0.5195 - val_accuracy: 0.8390\n",
      "Epoch 132/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.1995 - accuracy: 0.9138 - val_loss: 0.5308 - val_accuracy: 0.8240\n",
      "Epoch 133/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.2027 - accuracy: 0.9139 - val_loss: 0.5533 - val_accuracy: 0.8320\n",
      "Epoch 134/200\n",
      "10000/10000 [==============================] - 3s 314us/step - loss: 0.1963 - accuracy: 0.9175 - val_loss: 0.5187 - val_accuracy: 0.8260\n",
      "Epoch 135/200\n",
      "10000/10000 [==============================] - 3s 310us/step - loss: 0.1966 - accuracy: 0.9145 - val_loss: 0.5640 - val_accuracy: 0.8190\n",
      "Epoch 136/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.1958 - accuracy: 0.9135 - val_loss: 0.5395 - val_accuracy: 0.8280\n",
      "Epoch 137/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.1965 - accuracy: 0.9160 - val_loss: 0.5742 - val_accuracy: 0.8300\n",
      "Epoch 138/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.1976 - accuracy: 0.9124 - val_loss: 0.5437 - val_accuracy: 0.8270\n",
      "Epoch 139/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.1968 - accuracy: 0.9159 - val_loss: 0.5760 - val_accuracy: 0.8310\n",
      "Epoch 140/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.1959 - accuracy: 0.9148 - val_loss: 0.5630 - val_accuracy: 0.8250\n",
      "Epoch 141/200\n",
      "10000/10000 [==============================] - 3s 315us/step - loss: 0.1978 - accuracy: 0.9139 - val_loss: 0.5710 - val_accuracy: 0.8290\n",
      "Epoch 142/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.1956 - accuracy: 0.9181 - val_loss: 0.5925 - val_accuracy: 0.8210\n",
      "Epoch 143/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.1848 - accuracy: 0.9185 - val_loss: 0.5915 - val_accuracy: 0.8280\n",
      "Epoch 144/200\n",
      "10000/10000 [==============================] - 3s 312us/step - loss: 0.1830 - accuracy: 0.9204 - val_loss: 0.5560 - val_accuracy: 0.8210\n",
      "Epoch 145/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.1917 - accuracy: 0.9161 - val_loss: 0.5674 - val_accuracy: 0.8300\n",
      "Epoch 146/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.1864 - accuracy: 0.9190 - val_loss: 0.5596 - val_accuracy: 0.8250\n",
      "Epoch 147/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.1924 - accuracy: 0.9189 - val_loss: 0.5562 - val_accuracy: 0.8190\n",
      "Epoch 148/200\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.1836 - accuracy: 0.9217 - val_loss: 0.5538 - val_accuracy: 0.8240\n",
      "Epoch 149/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.1893 - accuracy: 0.9181 - val_loss: 0.5144 - val_accuracy: 0.8240\n",
      "Epoch 150/200\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.1851 - accuracy: 0.9184 - val_loss: 0.6331 - val_accuracy: 0.8240\n",
      "Epoch 151/200\n",
      "10000/10000 [==============================] - 3s 297us/step - loss: 0.1888 - accuracy: 0.9189 - val_loss: 0.5499 - val_accuracy: 0.8210\n",
      "Epoch 152/200\n",
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.1810 - accuracy: 0.9220 - val_loss: 0.6306 - val_accuracy: 0.8280\n",
      "Epoch 153/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.1787 - accuracy: 0.9288 - val_loss: 0.5383 - val_accuracy: 0.8140\n",
      "Epoch 154/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.1848 - accuracy: 0.9200 - val_loss: 0.5785 - val_accuracy: 0.8290\n",
      "Epoch 155/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.1807 - accuracy: 0.9239 - val_loss: 0.6068 - val_accuracy: 0.8330\n",
      "Epoch 156/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.1748 - accuracy: 0.9241 - val_loss: 0.5646 - val_accuracy: 0.8290\n",
      "Epoch 157/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.1822 - accuracy: 0.9228 - val_loss: 0.5907 - val_accuracy: 0.8220\n",
      "Epoch 158/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.1787 - accuracy: 0.9263 - val_loss: 0.5469 - val_accuracy: 0.8290\n",
      "Epoch 159/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.1737 - accuracy: 0.9245 - val_loss: 0.5936 - val_accuracy: 0.8320\n",
      "Epoch 160/200\n",
      "10000/10000 [==============================] - 3s 298us/step - loss: 0.1771 - accuracy: 0.9258 - val_loss: 0.5916 - val_accuracy: 0.8270\n",
      "Epoch 161/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.1813 - accuracy: 0.9215 - val_loss: 0.5836 - val_accuracy: 0.8300\n",
      "Epoch 162/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.1716 - accuracy: 0.9294 - val_loss: 0.5924 - val_accuracy: 0.8230\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.1745 - accuracy: 0.9286 - val_loss: 0.6031 - val_accuracy: 0.8320\n",
      "Epoch 164/200\n",
      "10000/10000 [==============================] - 3s 293us/step - loss: 0.1748 - accuracy: 0.9269 - val_loss: 0.6042 - val_accuracy: 0.8220\n",
      "Epoch 165/200\n",
      "10000/10000 [==============================] - 3s 297us/step - loss: 0.1776 - accuracy: 0.9270 - val_loss: 0.6086 - val_accuracy: 0.8270\n",
      "Epoch 166/200\n",
      "10000/10000 [==============================] - 3s 299us/step - loss: 0.1710 - accuracy: 0.9288 - val_loss: 0.6412 - val_accuracy: 0.8280\n",
      "Epoch 167/200\n",
      "10000/10000 [==============================] - 3s 295us/step - loss: 0.1676 - accuracy: 0.9290 - val_loss: 0.5976 - val_accuracy: 0.8200\n",
      "Epoch 168/200\n",
      "10000/10000 [==============================] - 3s 298us/step - loss: 0.1730 - accuracy: 0.9281 - val_loss: 0.5815 - val_accuracy: 0.8330\n",
      "Epoch 169/200\n",
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.1704 - accuracy: 0.9291 - val_loss: 0.5668 - val_accuracy: 0.8320\n",
      "Epoch 170/200\n",
      "10000/10000 [==============================] - 3s 295us/step - loss: 0.1672 - accuracy: 0.9339 - val_loss: 0.6130 - val_accuracy: 0.8250\n",
      "Epoch 171/200\n",
      "10000/10000 [==============================] - 3s 298us/step - loss: 0.1683 - accuracy: 0.9303 - val_loss: 0.5903 - val_accuracy: 0.8230\n",
      "Epoch 172/200\n",
      "10000/10000 [==============================] - 3s 295us/step - loss: 0.1670 - accuracy: 0.9310 - val_loss: 0.5755 - val_accuracy: 0.8260\n",
      "Epoch 173/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.1627 - accuracy: 0.9332 - val_loss: 0.5967 - val_accuracy: 0.8270\n",
      "Epoch 174/200\n",
      "10000/10000 [==============================] - 3s 298us/step - loss: 0.1553 - accuracy: 0.9340 - val_loss: 0.6187 - val_accuracy: 0.8270\n",
      "Epoch 175/200\n",
      "10000/10000 [==============================] - 3s 298us/step - loss: 0.1587 - accuracy: 0.9360 - val_loss: 0.6079 - val_accuracy: 0.8290\n",
      "Epoch 176/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.1601 - accuracy: 0.9351 - val_loss: 0.5690 - val_accuracy: 0.8270\n",
      "Epoch 177/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.1488 - accuracy: 0.9420 - val_loss: 0.6379 - val_accuracy: 0.8330\n",
      "Epoch 178/200\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.1477 - accuracy: 0.9402 - val_loss: 0.5661 - val_accuracy: 0.8360\n",
      "Epoch 179/200\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.1425 - accuracy: 0.9408 - val_loss: 0.6194 - val_accuracy: 0.8230\n",
      "Epoch 180/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.1479 - accuracy: 0.9401 - val_loss: 0.5520 - val_accuracy: 0.8310\n",
      "Epoch 181/200\n",
      "10000/10000 [==============================] - 3s 309us/step - loss: 0.1429 - accuracy: 0.9405 - val_loss: 0.5535 - val_accuracy: 0.8460\n",
      "Epoch 182/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.1386 - accuracy: 0.9463 - val_loss: 0.5268 - val_accuracy: 0.8450\n",
      "Epoch 183/200\n",
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.1400 - accuracy: 0.9474 - val_loss: 0.5453 - val_accuracy: 0.8320\n",
      "Epoch 184/200\n",
      "10000/10000 [==============================] - 3s 298us/step - loss: 0.1350 - accuracy: 0.9467 - val_loss: 0.5865 - val_accuracy: 0.8490\n",
      "Epoch 185/200\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.1315 - accuracy: 0.9487 - val_loss: 0.5664 - val_accuracy: 0.8450\n",
      "Epoch 186/200\n",
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.1326 - accuracy: 0.9483 - val_loss: 0.5491 - val_accuracy: 0.8550\n",
      "Epoch 187/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.1277 - accuracy: 0.9508 - val_loss: 0.5237 - val_accuracy: 0.8570\n",
      "Epoch 188/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.1212 - accuracy: 0.9532 - val_loss: 0.5626 - val_accuracy: 0.8670\n",
      "Epoch 189/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.1215 - accuracy: 0.9528 - val_loss: 0.6030 - val_accuracy: 0.8520\n",
      "Epoch 190/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.1199 - accuracy: 0.9547 - val_loss: 0.5687 - val_accuracy: 0.8580\n",
      "Epoch 191/200\n",
      "10000/10000 [==============================] - 3s 296us/step - loss: 0.1159 - accuracy: 0.9556 - val_loss: 0.5547 - val_accuracy: 0.8630\n",
      "Epoch 192/200\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.1145 - accuracy: 0.9551 - val_loss: 0.5276 - val_accuracy: 0.8540\n",
      "Epoch 193/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.1193 - accuracy: 0.9563 - val_loss: 0.4982 - val_accuracy: 0.8620\n",
      "Epoch 194/200\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.1128 - accuracy: 0.9591 - val_loss: 0.5958 - val_accuracy: 0.8710\n",
      "Epoch 195/200\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.1019 - accuracy: 0.9601 - val_loss: 0.5395 - val_accuracy: 0.8630\n",
      "Epoch 196/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.1069 - accuracy: 0.9621 - val_loss: 0.5297 - val_accuracy: 0.8570\n",
      "Epoch 197/200\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.1078 - accuracy: 0.9592 - val_loss: 0.5497 - val_accuracy: 0.8630\n",
      "Epoch 198/200\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.1060 - accuracy: 0.9602 - val_loss: 0.5795 - val_accuracy: 0.8660\n",
      "Epoch 199/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.1023 - accuracy: 0.9628 - val_loss: 0.5475 - val_accuracy: 0.8720\n",
      "Epoch 200/200\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.1036 - accuracy: 0.9629 - val_loss: 0.5204 - val_accuracy: 0.8730\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train, queries_train], answers_train, batch_size=32, epochs = 200, validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"chatbot.h5\"\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9736185e-15, 1.7839410e-15, 2.1506455e-15, ..., 9.9999416e-01,\n",
       "        2.0767147e-15, 1.9369223e-15],\n",
       "       [2.0673067e-16, 1.8996598e-16, 2.4513192e-16, ..., 9.9999750e-01,\n",
       "        2.2071269e-16, 2.0610547e-16],\n",
       "       [4.4020933e-12, 4.5647236e-12, 4.5311879e-12, ..., 9.2892252e-02,\n",
       "        4.0999322e-12, 3.9836255e-12],\n",
       "       ...,\n",
       "       [1.6800756e-17, 1.6208368e-17, 2.0859326e-17, ..., 9.9999905e-01,\n",
       "        1.7694034e-17, 1.6881896e-17],\n",
       "       [2.7998546e-18, 1.7745235e-18, 2.5474884e-18, ..., 1.0147299e-05,\n",
       "        1.9701616e-18, 1.7660685e-18],\n",
       "       [1.8547856e-16, 2.3862297e-16, 2.3824914e-16, ..., 9.9988019e-01,\n",
       "        2.3290508e-16, 2.3590140e-16]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9736185e-15, 1.7839410e-15, 2.1506455e-15, 2.1595897e-15,\n",
       "       2.1324603e-15, 1.6814412e-15, 1.9469525e-15, 1.9015468e-15,\n",
       "       2.0342957e-15, 2.4605591e-15, 1.7642742e-15, 1.7650146e-15,\n",
       "       2.1815319e-15, 1.8560950e-15, 2.0655589e-15, 2.1137680e-15,\n",
       "       1.6580905e-15, 2.1186278e-15, 2.3023291e-15, 1.5979313e-15,\n",
       "       1.8410467e-15, 1.9705114e-15, 2.0871980e-15, 5.8121541e-06,\n",
       "       1.7917294e-15, 1.8886067e-15, 1.5899416e-15, 1.6329385e-15,\n",
       "       1.7963282e-15, 1.9750343e-15, 2.0749489e-15, 2.1716345e-15,\n",
       "       1.9070093e-15, 2.0780143e-15, 1.9948422e-15, 9.9999416e-01,\n",
       "       2.0767147e-15, 1.9369223e-15], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'John', 'in', 'the', 'kitchen', '?']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in tokenizer.word_index.items():\n",
    "    if val==val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999416"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = \"John left the kitchen . Sandra dropped football in the garden .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(), my_question.split(), \"yes\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['John',\n",
       "   'left',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'dropped',\n",
       "   'football',\n",
       "   'in',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.'],\n",
       "  ['Is', 'the', 'football', 'in', 'the', 'garden', '?'],\n",
       "  'yes')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_ques, my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = model.predict(([my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.50342842e-16, 9.35506862e-17, 1.30192802e-16, 1.15647989e-16,\n",
       "        1.38216256e-16, 1.37186687e-16, 1.02242528e-16, 1.12935829e-16,\n",
       "        1.31055346e-16, 1.08706733e-16, 1.46680973e-16, 1.21368320e-16,\n",
       "        1.04892974e-16, 1.13387788e-16, 1.32678606e-16, 1.12469789e-16,\n",
       "        1.05696305e-16, 1.87799725e-16, 1.05912642e-16, 1.44303934e-16,\n",
       "        1.15982435e-16, 1.05766483e-16, 1.17526999e-16, 9.99957442e-01,\n",
       "        1.51788106e-16, 1.09038154e-16, 1.56417114e-16, 1.10293589e-16,\n",
       "        1.25551948e-16, 1.10339455e-16, 1.41719200e-16, 1.14719125e-16,\n",
       "        1.53882871e-16, 1.13192454e-16, 1.35765922e-16, 4.25660437e-05,\n",
       "        1.08632942e-16, 9.24385717e-17]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99995744"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[0][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitb17fdf98e28c491e8ebba8b35e662a75"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
